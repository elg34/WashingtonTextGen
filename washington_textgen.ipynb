{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import h5py\n",
    "from collections import Counter\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.models import load_model\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from keras import optimizers\n",
    "import pickle\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def preproc(text):\n",
    "    'preprocessing of large text string'\n",
    "    text = re.sub(' Mr.', ' Mr', text)\n",
    "    text = re.sub(' Mrs.', ' Mrs', text)\n",
    "    text = re.sub(' Messrs.', ' Messrs', text)\n",
    "    text = text.lower()\n",
    "    text = re.sub('\\[(.*?)\\]', '', text)\n",
    "    text = re.sub('\\n\\n', ' ', text)\n",
    "    text = re.sub('\\n', ' ', text)\n",
    "    text = re.sub(',', '', text)\n",
    "    text = re.sub(' {2,}', '', text)\n",
    "    text = re.sub('_', '', text)\n",
    "    text = re.sub(';', '', text)\n",
    "    text = re.sub('_figure_', '', text)\n",
    "    text = re.sub('\\d+','',text)\n",
    "    return text\n",
    "\n",
    "def get_dicts(rawwords):\n",
    "        # get word counts and dictionaries and make a category for rare words\n",
    "        word_counts = Counter(word for word in rawwords)\n",
    "        words = [ word if word_counts[word]>5 else 'RARE' for word in rawwords ]\n",
    "        unique_words = sorted(list(set(words)))\n",
    "        word_to_int = dict((c, i) for i, c in enumerate(unique_words))\n",
    "        int_to_word = dict((i, c) for i, c in enumerate(unique_words))\n",
    "        n_words = len(words)\n",
    "        n_uwords = len(unique_words)\n",
    "        print('Total Words (without rare words): ', n_words)\n",
    "        print('Unique Words (without rare words): ', n_uwords)\n",
    "        return words,n_words,n_uwords,word_to_int,int_to_word\n",
    "\n",
    "def load_data(name):\n",
    "        with open (name, 'rb') as fp:\n",
    "            text = pickle.load(fp)\n",
    "        print('using saved data... (',len(text),')')\n",
    "        return text\n",
    "    \n",
    "# get all words in target text file, plus all files in a directory for optional pre-training\n",
    "def get_data(targetname,pretrains = None):\n",
    "    'load text from file, optional pretraining'\n",
    "    rawwords=[]\n",
    "    text = open(targetname).read() # now do the same for target file\n",
    "    text = preproc(text)\n",
    "    wds = re.findall(r\"[\\w']+|[.,!?;]\", text)\n",
    "    print('Words in target set: ', len(wds))\n",
    "    for wd in wds:\n",
    "        rawwords.append(wd)     \n",
    "    with open('text_main.pkl', 'wb') as fp:\n",
    "        pickle.dump(rawwords, fp)\n",
    "    \n",
    "    if pretrains: # optional\n",
    "        filename = glob.glob(pretrains) # get directory and file ending for pretraining files\n",
    "        count=0\n",
    "        for i in filename:\n",
    "            text = open(i).read()\n",
    "            text = preproc(text) # preprocess file text\n",
    "            wds = re.findall(r\"[\\w']+|[.,!?;]\", text) # split text into individual words\n",
    "            for wd in wds:\n",
    "                rawwords.append(wd) # append individual words to our raw training array\n",
    "            count +=1\n",
    "            print('loading file...', count+1, '/',len(filename),' :: ',i)\n",
    "        print('Words in pretraining set: ', len(rawwords))\n",
    "        with open('text_pretrain.pkl', 'wb') as fp:\n",
    "            pickle.dump(rawwords, fp)\n",
    "    return rawwords\n",
    "    \n",
    "def predict_words(npred,div):\n",
    "        start = np.random.randint(0, len(words)-seq_length) # pick a random seed\n",
    "        pattern = words[start:start+seq_length] # get a full sequence\n",
    "        print('Seed: \"' + ' '.join(pattern) + '\"')\n",
    "        for i in range(npred):\n",
    "                x_pred = np.zeros((1, seq_length, len(sorted(list(set(words))))))\n",
    "                for t, wd in enumerate(pattern):\n",
    "                        x_pred[0, t, word_to_int[wd]] = 1.\n",
    "                preds = model.predict(x_pred, verbose=0)[0]\n",
    "                preds = np.asarray(preds).astype('float64')\n",
    "                preds = np.log(preds)/div\n",
    "                exp_preds = np.exp(preds)\n",
    "                preds = exp_preds / np.sum(exp_preds)\n",
    "                res = int_to_word[np.argmax(np.random.multinomial(1, preds, 1))]\n",
    "                while res=='RARE': # or res==pattern[-1]: # if model predicts rare, sample again until it finds a more frequent word\n",
    "                        res = int_to_word[np.argmax(np.random.multinomial(1, preds,1))]\n",
    "                pattern.append(res)\n",
    "                pattern = pattern[1:]\n",
    "                sys.stdout.write(res+' ')\n",
    "                sys.stdout.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words in target set:  228311\n",
      "using saved data... ( 228311 )\n",
      "Total Words (without rare words):  228311\n",
      "Unique Words (without rare words):  2897\n"
     ]
    }
   ],
   "source": [
    "# get text & words\n",
    "raw_pretrain = get_data('gwtext.txt')\n",
    "rawwords = load_data('text_main.pkl')\n",
    "words,n_words,n_uwords,word_to_int,int_to_word = get_dicts(rawwords)\n",
    "\n",
    "batch_size = 100 # how many sequences to train concurrently per weight update\n",
    "seq_length = 30 # number of words per training sequence\n",
    "\n",
    "n_examples = len(words)-seq_length # total number of available example sequences\n",
    "n_batches = n_examples/batch_size # how many batches from full set of examples\n",
    "\n",
    "model = load_model('modelE4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: \"to fear but for the general service and no hopes but the advantages it will RARE from the success of our operations therefore cannot be supposed to have any private\"\n",
      "have cannot out of all exclusive money more pleasure by least other attempting up captain ship and the madam of matter seek my could a court of drafts . little esteem done this is that an acquainted seven the assistance were a go between this wishes that it been though it . last put that mr blank flat down to town that to be orders of an considerable opinion hand to them to general a cause way of the many . i shall myself to bring want and building that they from it however my getting how sent if i "
     ]
    }
   ],
   "source": [
    "predict_words(100,1.0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
